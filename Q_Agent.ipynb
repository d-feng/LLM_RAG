{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "765bb53e-7014-46ce-a5d9-01367aa8c6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "load_dotenv(\".env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57630322-3f58-46cc-b1ab-9cad6aac8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmi import CommonLLMNames\n",
    "\n",
    "llm_openai = CommonLLMNames.OPENAI_TEST.value\n",
    "llm_anthropic = CommonLLMNames.ANTHROPIC_TEST.value\n",
    "\n",
    "# Create the `papers` directory if it doesn't exist\n",
    "os.makedirs(\"papers\", exist_ok=True)\n",
    "\n",
    "# Download the paper from arXiv and save it to the `papers` directory\n",
    "url = \"https://arxiv.org/pdf/2407.01603\"\n",
    "async with aiohttp.ClientSession() as session, session.get(url, timeout=60) as response:\n",
    "    content = await response.read()\n",
    "    with open(\"papers/2407.01603.pdf\", \"wb\") as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c13dd8-0082-4b4d-acf0-1d4a5dd431e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "from paperqa.prompts import (\n",
    "    CONTEXT_INNER_PROMPT,\n",
    "    CONTEXT_OUTER_PROMPT,\n",
    "    citation_prompt,\n",
    "    default_system_prompt,\n",
    "    env_reset_prompt,\n",
    "    env_system_prompt,\n",
    "    qa_prompt,\n",
    "    select_paper_prompt,\n",
    "    structured_citation_prompt,\n",
    "    summary_json_prompt,\n",
    "    summary_json_system_prompt,\n",
    "    summary_prompt,\n",
    ")\n",
    "from paperqa.settings import (\n",
    "    AgentSettings,\n",
    "    AnswerSettings,\n",
    "    IndexSettings,\n",
    "    ParsingSettings,\n",
    "    PromptSettings,\n",
    "    Settings,\n",
    ")\n",
    "\n",
    "settings = Settings(\n",
    "    llm=llm_openai,\n",
    "    llm_config={\n",
    "        \"model_list\": [\n",
    "            {\n",
    "                \"model_name\": llm_openai,\n",
    "                \"litellm_params\": {\n",
    "                    \"model\": llm_openai,\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"max_tokens\": 4096,\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "        \"rate_limit\": {\n",
    "            llm_openai: \"30000 per 1 minute\",\n",
    "        },\n",
    "    },\n",
    "    summary_llm=llm_openai,\n",
    "    summary_llm_config={\n",
    "        \"rate_limit\": {\n",
    "            llm_openai: \"30000 per 1 minute\",\n",
    "        },\n",
    "    },\n",
    "    embedding=\"text-embedding-3-small\",\n",
    "    embedding_config={},\n",
    "    temperature=0.1,\n",
    "    batch_size=1,\n",
    "    verbosity=1,\n",
    "    manifest_file=None,\n",
    "    paper_directory=pathlib.Path.cwd().joinpath(\"papers\"),\n",
    "    index_directory=pathlib.Path.cwd().joinpath(\"papers/index\"),\n",
    "    answer=AnswerSettings(\n",
    "        evidence_k=10,\n",
    "        evidence_detailed_citations=True,\n",
    "        evidence_retrieval=True,\n",
    "        evidence_summary_length=\"about 100 words\",\n",
    "        evidence_skip_summary=False,\n",
    "        answer_max_sources=5,\n",
    "        max_answer_attempts=None,\n",
    "        answer_length=\"about 200 words, but can be longer\",\n",
    "        max_concurrent_requests=10,\n",
    "    ),\n",
    "    parsing=ParsingSettings(\n",
    "        chunk_size=5000,\n",
    "        overlap=250,\n",
    "        citation_prompt=citation_prompt,\n",
    "        structured_citation_prompt=structured_citation_prompt,\n",
    "    ),\n",
    "    prompts=PromptSettings(\n",
    "        summary=summary_prompt,\n",
    "        qa=qa_prompt,\n",
    "        select=select_paper_prompt,\n",
    "        pre=None,\n",
    "        post=None,\n",
    "        system=default_system_prompt,\n",
    "        use_json=True,\n",
    "        summary_json=summary_json_prompt,\n",
    "        summary_json_system=summary_json_system_prompt,\n",
    "        context_outer=CONTEXT_OUTER_PROMPT,\n",
    "        context_inner=CONTEXT_INNER_PROMPT,\n",
    "    ),\n",
    "    agent=AgentSettings(\n",
    "        agent_llm=llm_openai,\n",
    "        agent_llm_config={\n",
    "            \"model_list\": [\n",
    "                {\n",
    "                    \"model_name\": llm_openai,\n",
    "                    \"litellm_params\": {\n",
    "                        \"model\": llm_openai,\n",
    "                    },\n",
    "                }\n",
    "            ],\n",
    "            \"rate_limit\": {\n",
    "                llm_openai: \"30000 per 1 minute\",\n",
    "            },\n",
    "        },\n",
    "        agent_prompt=env_reset_prompt,\n",
    "        agent_system_prompt=env_system_prompt,\n",
    "        search_count=8,\n",
    "        index=IndexSettings(\n",
    "            paper_directory=pathlib.Path.cwd().joinpath(\"papers\"),\n",
    "            index_directory=pathlib.Path.cwd().joinpath(\"papers/index\"),\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bf3c853-e055-4cf1-8c10-171533c326ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PaperQA version: 5.20.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:21] </span>Beginning agent <span style=\"color: #008000; text-decoration-color: #008000\">'ToolSelector'</span> run with question <span style=\"color: #008000; text-decoration-color: #008000\">'What are the most relevant language models used for </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">chemistry?'</span> and full settings <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'llm'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'llm_config'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model_list'</span>:            \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'litellm_params'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>,         \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'max_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span><span style=\"font-weight: bold\">}}]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rate_limit'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'30000 per 1 </span>       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">minute'</span><span style=\"font-weight: bold\">}}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'summary_llm'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'summary_llm_config'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'rate_limit'</span>:                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'30000 per 1 minute'</span><span style=\"font-weight: bold\">}}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'embedding'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text-embedding-3-small'</span>,               \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'embedding_config'</span>: <span style=\"font-weight: bold\">{}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'texts_index_mmr_lambda'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'verbosity'</span>:\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'evidence_k'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'evidence_detailed_citations'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'evidence_retrieval'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'evidence_summary_length'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'about 100 words'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'evidence_skip_summary'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'answer_max_sources'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'max_answer_attempts'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'answer_length'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'about 200 words, but can be longer'</span>,                     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'max_concurrent_requests'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'answer_filter_extra_background'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'get_evidence_if_no_contexts'</span>:  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'parsing'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'chunk_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5000</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'page_size_limit'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1280000</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'use_doc_details'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'overlap'</span>:  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">250</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'citation_prompt'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Provide the citation for the following text in MLA Format. Do not write an </span>    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">introductory sentence. If reporting date accessed, the current year is 2025\\n\\n{text}\\n\\nCitation:'</span>,    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'structured_citation_prompt'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Extract the title, authors, and doi as a JSON from this MLA citation. If </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">any field can not be found, return it as null. Use title, authors, and doi as keys, author's value </span>     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">should be a list of authors. {citation}\\n\\nCitation JSON:\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'disable_doc_valid_check'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,           \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'defer_embedding'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunking_algorithm'</span>: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">ChunkingOptions.SIMPLE_OVERLAP:</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'simple_overlap'</span><span style=\"font-weight: bold\">&gt;</span>,     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'doc_filters'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'use_human_readable_clinical_trials'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'prompts'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'summary'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Summarize the</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">excerpt below to help answer a question.\\n\\nExcerpt from </span>                                               \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">{citation}\\n\\n----\\n\\n{text}\\n\\n----\\n\\nQuestion: {question}\\n\\nDo not directly answer the question, </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">instead summarize to give evidence to help answer the question. Stay detailed; report specific numbers, </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">equations, or direct quotes (marked with quotation marks). Reply \"Not applicable\" if the excerpt is </span>    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">irrelevant. At the end of your response, provide an integer score from 1-10 on a newline indicating </span>    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">relevance to question. Do not explain your score.\\n\\nRelevant Information Summary ({summary_length}):'</span>, \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'qa'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Answer the question below with the context.\\n\\nContext (with relevance </span>                          \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">scores):\\n\\n{context}\\n\\n----\\n\\nQuestion: {question}\\n\\nWrite an answer based on the context. If the </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">context provides insufficient information reply \"I cannot answer.\" For each part of your answer, </span>       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">indicate which sources most support it via citation keys at the end of sentences, like </span>                 \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">{example_citation}. Only cite from the context below and only use the valid keys. Write in the style of </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">a Wikipedia article, with concise sentences and coherent paragraphs. The context comes from a variety of</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">sources and is only a summary, so there may inaccuracies or ambiguities. If quotes are present and </span>     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">relevant, use them in the answer. This answer will go directly onto Wikipedia, so do not add any </span>       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">extraneous information.\\n\\n{prior_answer_prompt}Answer ({answer_length}):'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'answer_iteration_prompt'</span>:  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'You are iterating on a prior answer, with a potentially different context:\\n\\n{prior_answer}\\n\\nCreate </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">a new answer only using keys and data from the included context. You can not use context keys from the </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">prior answer which are not also included in the above context.\\n\\n'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'select'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Select papers that may </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">help answer the question below. Papers are listed as $KEY: $PAPER_INFO. Return a list of keys, separated</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">by commas. Return \"None\", if no papers are applicable. Choose papers that are relevant, from reputable </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">sources, and timely (if the question requires timely information).\\n\\nQuestion: {question}\\n\\nPapers: </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">{papers}\\n\\nSelected keys:'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pre'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'post'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'system'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Answer in a direct and concise tone. </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">Your audience is an expert, so be highly specific. If there are ambiguous terms or acronyms, first </span>     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">define them.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'use_json'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'summary_json'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Excerpt from </span>                                         \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">{citation}\\n\\n----\\n\\n{text}\\n\\n----\\n\\nQuestion: {question}\\n\\n'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'summary_json_system'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Provide a </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">summary of the relevant information that could help answer the question based on the excerpt. Respond </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">with the following JSON format:\\n\\n{{\\n  \"summary\": \"...\",\\n  \"relevance_score\": \"...\"\\n}}\\n\\nwhere </span>    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">`summary` is relevant information from the text - {summary_length} words. `relevance_score` is an </span>      \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">integer 1-10 for the relevance of `summary` to the question.\\n'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'context_outer'</span>:                       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'{context_str}\\n\\nValid Keys: {valid_keys}'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'context_inner'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{name}: {text}\\nFrom {citation}'</span><span style=\"font-weight: bold\">}</span>,       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'agent'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'agent_llm'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'agent_llm_config'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model_list'</span>: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>:     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'litellm_params'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span><span style=\"font-weight: bold\">}}]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rate_limit'</span>:        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'30000 per 1 minute'</span><span style=\"font-weight: bold\">}}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'agent_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ToolSelector'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'agent_config'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'agent_system_prompt'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'You are a helpful AI assistant.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'agent_prompt'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Use the tools to answer the </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">question: {question}\\n\\nWhen the answer looks sufficient, you can terminate by calling the </span>             \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">{complete_tool_name} tool. If the answer does not look sufficient, and you have already tried to answer </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">several times with different evidence, terminate by calling the {complete_tool_name} tool. The current </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">status of evidence/papers/cost is {status}'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'return_paper_metadata'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'search_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,         \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'wipe_context_on_answer_failure'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'agent_evidence_n'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'timeout'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'should_pre_search'</span>:   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'tool_names'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'max_timesteps'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'paper_directory'</span>:            \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">WindowsPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'C:/Users/difen/papers'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'manifest_file'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index_directory'</span>:                         \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">WindowsPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'C:/Users/difen/papers/index'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'use_absolute_paper_directory'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,                      \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'recurse_subdirectories'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'concurrency'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'sync_with_paper_directory'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>,  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'rebuild_index'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'md5'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'8fc8d8403d490381ca8968ef0afbff98'</span><span style=\"font-weight: bold\">}</span>.                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:21]\u001b[0m\u001b[2;36m \u001b[0mBeginning agent \u001b[32m'ToolSelector'\u001b[0m run with question \u001b[32m'What are the most relevant language models used for \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mchemistry?'\u001b[0m and full settings \u001b[1m{\u001b[0m\u001b[32m'llm'\u001b[0m: \u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m, \u001b[32m'llm_config'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'model_list'\u001b[0m:            \n",
       "\u001b[2;36m           \u001b[0m\u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'model_name'\u001b[0m: \u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m, \u001b[32m'litellm_params'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'model'\u001b[0m: \u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m,         \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'temperature'\u001b[0m: \u001b[1;36m0.1\u001b[0m, \u001b[32m'max_tokens'\u001b[0m: \u001b[1;36m4096\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'rate_limit'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m: \u001b[32m'30000 per 1 \u001b[0m       \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mminute'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'summary_llm'\u001b[0m: \u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m, \u001b[32m'summary_llm_config'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'rate_limit'\u001b[0m:                \n",
       "\u001b[2;36m           \u001b[0m\u001b[1m{\u001b[0m\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m: \u001b[32m'30000 per 1 minute'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'embedding'\u001b[0m: \u001b[32m'text-embedding-3-small'\u001b[0m,               \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'embedding_config'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'temperature'\u001b[0m: \u001b[1;36m0.1\u001b[0m, \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'texts_index_mmr_lambda'\u001b[0m: \u001b[1;36m1.0\u001b[0m, \u001b[32m'verbosity'\u001b[0m:\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36m1\u001b[0m, \u001b[32m'answer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'evidence_k'\u001b[0m: \u001b[1;36m10\u001b[0m, \u001b[32m'evidence_detailed_citations'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'evidence_retrieval'\u001b[0m: \u001b[3;92mTrue\u001b[0m,        \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'evidence_summary_length'\u001b[0m: \u001b[32m'about 100 words'\u001b[0m, \u001b[32m'evidence_skip_summary'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'answer_max_sources'\u001b[0m: \u001b[1;36m5\u001b[0m,  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'max_answer_attempts'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'answer_length'\u001b[0m: \u001b[32m'about 200 words, but can be longer'\u001b[0m,                     \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'max_concurrent_requests'\u001b[0m: \u001b[1;36m10\u001b[0m, \u001b[32m'answer_filter_extra_background'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'get_evidence_if_no_contexts'\u001b[0m:  \n",
       "\u001b[2;36m           \u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'parsing'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'chunk_size'\u001b[0m: \u001b[1;36m5000\u001b[0m, \u001b[32m'page_size_limit'\u001b[0m: \u001b[1;36m1280000\u001b[0m, \u001b[32m'use_doc_details'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'overlap'\u001b[0m:  \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36m250\u001b[0m, \u001b[32m'citation_prompt'\u001b[0m: \u001b[32m'Provide the citation for the following text in MLA Format. Do not write an \u001b[0m    \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mintroductory sentence. If reporting date accessed, the current year is 2025\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nCitation:'\u001b[0m,    \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'structured_citation_prompt'\u001b[0m: \u001b[32m\"Extract the title, authors, and doi as a JSON from this MLA citation. If \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32many field can not be found, return it as null. Use title, authors, and doi as keys, author's value \u001b[0m     \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mshould be a list of authors. \u001b[0m\u001b[32m{\u001b[0m\u001b[32mcitation\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nCitation JSON:\"\u001b[0m, \u001b[32m'disable_doc_valid_check'\u001b[0m: \u001b[3;91mFalse\u001b[0m,           \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'defer_embedding'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'chunking_algorithm'\u001b[0m: \u001b[1m<\u001b[0m\u001b[1;95mChunkingOptions.SIMPLE_OVERLAP:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'simple_overlap'\u001b[0m\u001b[1m>\u001b[0m,     \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'doc_filters'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'use_human_readable_clinical_trials'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'prompts'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'summary'\u001b[0m: \u001b[32m'Summarize the\u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mexcerpt below to help answer a question.\\n\\nExcerpt from \u001b[0m                                               \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m{\u001b[0m\u001b[32mcitation\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n----\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n----\\n\\nQuestion: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nDo not directly answer the question, \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32minstead summarize to give evidence to help answer the question. Stay detailed; report specific numbers, \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mequations, or direct quotes \u001b[0m\u001b[32m(\u001b[0m\u001b[32mmarked with quotation marks\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Reply \"Not applicable\" if the excerpt is \u001b[0m    \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mirrelevant. At the end of your response, provide an integer score from 1-10 on a newline indicating \u001b[0m    \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mrelevance to question. Do not explain your score.\\n\\nRelevant Information Summary \u001b[0m\u001b[32m(\u001b[0m\u001b[32m{\u001b[0m\u001b[32msummary_length\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:'\u001b[0m, \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'qa'\u001b[0m: \u001b[32m'Answer the question below with the context.\\n\\nContext \u001b[0m\u001b[32m(\u001b[0m\u001b[32mwith relevance \u001b[0m                          \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mscores\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mcontext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n----\\n\\nQuestion: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nWrite an answer based on the context. If the \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mcontext provides insufficient information reply \"I cannot answer.\" For each part of your answer, \u001b[0m       \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mindicate which sources most support it via citation keys at the end of sentences, like \u001b[0m                 \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m{\u001b[0m\u001b[32mexample_citation\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. Only cite from the context below and only use the valid keys. Write in the style of \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32ma Wikipedia article, with concise sentences and coherent paragraphs. The context comes from a variety of\u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32msources and is only a summary, so there may inaccuracies or ambiguities. If quotes are present and \u001b[0m     \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mrelevant, use them in the answer. This answer will go directly onto Wikipedia, so do not add any \u001b[0m       \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mextraneous information.\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mprior_answer_prompt\u001b[0m\u001b[32m}\u001b[0m\u001b[32mAnswer \u001b[0m\u001b[32m(\u001b[0m\u001b[32m{\u001b[0m\u001b[32manswer_length\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:'\u001b[0m, \u001b[32m'answer_iteration_prompt'\u001b[0m:  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'You are iterating on a prior answer, with a potentially different context:\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mprior_answer\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nCreate \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32ma new answer only using keys and data from the included context. You can not use context keys from the \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mprior answer which are not also included in the above context.\\n\\n'\u001b[0m, \u001b[32m'select'\u001b[0m: \u001b[32m'Select papers that may \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mhelp answer the question below. Papers are listed as $KEY: $PAPER_INFO. Return a list of keys, separated\u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mby commas. Return \"None\", if no papers are applicable. Choose papers that are relevant, from reputable \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32msources, and timely \u001b[0m\u001b[32m(\u001b[0m\u001b[32mif the question requires timely information\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\\nQuestion: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nPapers: \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m{\u001b[0m\u001b[32mpapers\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nSelected keys:'\u001b[0m, \u001b[32m'pre'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'post'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'system'\u001b[0m: \u001b[32m'Answer in a direct and concise tone. \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mYour audience is an expert, so be highly specific. If there are ambiguous terms or acronyms, first \u001b[0m     \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mdefine them.'\u001b[0m, \u001b[32m'use_json'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'summary_json'\u001b[0m: \u001b[32m'Excerpt from \u001b[0m                                         \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m{\u001b[0m\u001b[32mcitation\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n----\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n----\\n\\nQuestion: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n'\u001b[0m, \u001b[32m'summary_json_system'\u001b[0m: \u001b[32m'Provide a \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32msummary of the relevant information that could help answer the question based on the excerpt. Respond \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mwith the following JSON format:\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n  \"summary\": \"...\",\\n  \"relevance_score\": \"...\"\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nwhere \u001b[0m    \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m`summary` is relevant information from the text - \u001b[0m\u001b[32m{\u001b[0m\u001b[32msummary_length\u001b[0m\u001b[32m}\u001b[0m\u001b[32m words. `relevance_score` is an \u001b[0m      \n",
       "\u001b[2;36m           \u001b[0m\u001b[32minteger 1-10 for the relevance of `summary` to the question.\\n'\u001b[0m, \u001b[32m'context_outer'\u001b[0m:                       \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mcontext_str\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nValid Keys: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mvalid_keys\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'context_inner'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mname\u001b[0m\u001b[32m}\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\nFrom \u001b[0m\u001b[32m{\u001b[0m\u001b[32mcitation\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m,       \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'agent'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'agent_llm'\u001b[0m: \u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m, \u001b[32m'agent_llm_config'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'model_list'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'model_name'\u001b[0m:     \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m, \u001b[32m'litellm_params'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'model'\u001b[0m: \u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'rate_limit'\u001b[0m:        \n",
       "\u001b[2;36m           \u001b[0m\u001b[1m{\u001b[0m\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m: \u001b[32m'30000 per 1 minute'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'agent_type'\u001b[0m: \u001b[32m'ToolSelector'\u001b[0m, \u001b[32m'agent_config'\u001b[0m: \u001b[3;35mNone\u001b[0m,  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'agent_system_prompt'\u001b[0m: \u001b[32m'You are a helpful AI assistant.'\u001b[0m, \u001b[32m'agent_prompt'\u001b[0m: \u001b[32m'Use the tools to answer the \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mquestion: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nWhen the answer looks sufficient, you can terminate by calling the \u001b[0m             \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m{\u001b[0m\u001b[32mcomplete_tool_name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m tool. If the answer does not look sufficient, and you have already tried to answer \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mseveral times with different evidence, terminate by calling the \u001b[0m\u001b[32m{\u001b[0m\u001b[32mcomplete_tool_name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m tool. The current \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mstatus of evidence/papers/cost is \u001b[0m\u001b[32m{\u001b[0m\u001b[32mstatus\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'return_paper_metadata'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'search_count'\u001b[0m: \u001b[1;36m8\u001b[0m,         \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'wipe_context_on_answer_failure'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'agent_evidence_n'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'timeout'\u001b[0m: \u001b[1;36m500.0\u001b[0m, \u001b[32m'should_pre_search'\u001b[0m:   \n",
       "\u001b[2;36m           \u001b[0m\u001b[3;91mFalse\u001b[0m, \u001b[32m'tool_names'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'max_timesteps'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'index'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'name'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'paper_directory'\u001b[0m:            \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;35mWindowsPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'C:/Users/difen/papers'\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'manifest_file'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'index_directory'\u001b[0m:                         \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;35mWindowsPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'C:/Users/difen/papers/index'\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'use_absolute_paper_directory'\u001b[0m: \u001b[3;91mFalse\u001b[0m,                      \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'recurse_subdirectories'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'concurrency'\u001b[0m: \u001b[1;36m5\u001b[0m, \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'sync_with_paper_directory'\u001b[0m: \u001b[3;92mTrue\u001b[0m\u001b[1m}\u001b[0m,  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'rebuild_index'\u001b[0m: \u001b[3;92mTrue\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'md5'\u001b[0m: \u001b[32m'8fc8d8403d490381ca8968ef0afbff98'\u001b[0m\u001b[1m}\u001b[0m.                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>New file to index: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2407.01603</span>.pdf<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mNew file to index: \u001b[1;36m2407.01603\u001b[0m.pdf\u001b[33m...\u001b[0m                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:25] </span>SEMANTIC_SCHOLAR_API_KEY environment variable not set. Semantic Scholar API rate limits may apply.      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:25]\u001b[0m\u001b[2;36m \u001b[0mSEMANTIC_SCHOLAR_API_KEY environment variable not set. Semantic Scholar API rate limits may apply.      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>CROSSREF_MAILTO environment variable not set. Crossref API rate limits may apply.                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mCROSSREF_MAILTO environment variable not set. Crossref API rate limits may apply.                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>CROSSREF_API_KEY environment variable not set. Crossref API rate limits may apply.                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mCROSSREF_API_KEY environment variable not set. Crossref API rate limits may apply.                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:26] </span>Metadata not found for arXiv:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2407.</span>01603v3 in CrossrefProvider.                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:26]\u001b[0m\u001b[2;36m \u001b[0mMetadata not found for arXiv:\u001b[1;36m2407.\u001b[0m01603v3 in CrossrefProvider.                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Metadata not found for arXiv:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2407.</span>01603v3 in SemanticScholarProvider.                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mMetadata not found for arXiv:\u001b[1;36m2407.\u001b[0m01603v3 in SemanticScholarProvider.                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:34] </span>Complete <span style=\"font-weight: bold\">(</span>A Review of Large Language Models and Autonomous Agents in Chemistry<span style=\"font-weight: bold\">)</span>.                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:34]\u001b[0m\u001b[2;36m \u001b[0mComplete \u001b[1m(\u001b[0mA Review of Large Language Models and Autonomous Agents in Chemistry\u001b[1m)\u001b[0m.                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:36] </span>Starting paper search for <span style=\"color: #008000; text-decoration-color: #008000\">'language models in chemistry'</span>.                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:36]\u001b[0m\u001b[2;36m \u001b[0mStarting paper search for \u001b[32m'language models in chemistry'\u001b[0m.                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>paper_search for query <span style=\"color: #008000; text-decoration-color: #008000\">'language models in chemistry'</span> and offset <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> returned <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> papers.                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mpaper_search for query \u001b[32m'language models in chemistry'\u001b[0m and offset \u001b[1;36m0\u001b[0m returned \u001b[1;36m1\u001b[0m papers.                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Status: Paper <span style=\"color: #808000; text-decoration-color: #808000\">Count</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> | Relevant <span style=\"color: #808000; text-decoration-color: #808000\">Papers</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> | Current <span style=\"color: #808000; text-decoration-color: #808000\">Evidence</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> | Current <span style=\"color: #808000; text-decoration-color: #808000\">Cost</span>=$<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0001</span>                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mStatus: Paper \u001b[33mCount\u001b[0m=\u001b[1;36m1\u001b[0m | Relevant \u001b[33mPapers\u001b[0m=\u001b[1;36m0\u001b[0m | Current \u001b[33mEvidence\u001b[0m=\u001b[1;36m0\u001b[0m | Current \u001b[33mCost\u001b[0m=$\u001b[1;36m0.0001\u001b[0m                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:37] </span>gather_evidence starting for question <span style=\"color: #008000; text-decoration-color: #008000\">'What are the most relevant language models used for chemistry?'</span>. \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:37]\u001b[0m\u001b[2;36m \u001b[0mgather_evidence starting for question \u001b[32m'What are the most relevant language models used for chemistry?'\u001b[0m. \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:42] </span>Status: Paper <span style=\"color: #808000; text-decoration-color: #808000\">Count</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> | Relevant <span style=\"color: #808000; text-decoration-color: #808000\">Papers</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> | Current <span style=\"color: #808000; text-decoration-color: #808000\">Evidence</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> | Current <span style=\"color: #808000; text-decoration-color: #808000\">Cost</span>=$<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0033</span>                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:42]\u001b[0m\u001b[2;36m \u001b[0mStatus: Paper \u001b[33mCount\u001b[0m=\u001b[1;36m1\u001b[0m | Relevant \u001b[33mPapers\u001b[0m=\u001b[1;36m1\u001b[0m | Current \u001b[33mEvidence\u001b[0m=\u001b[1;36m10\u001b[0m | Current \u001b[33mCost\u001b[0m=$\u001b[1;36m0.0033\u001b[0m                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Generating answer for <span style=\"color: #008000; text-decoration-color: #008000\">'What are the most relevant language models used for chemistry?'</span>.                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mGenerating answer for \u001b[32m'What are the most relevant language models used for chemistry?'\u001b[0m.                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:55] </span>Status: Paper <span style=\"color: #808000; text-decoration-color: #808000\">Count</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> | Relevant <span style=\"color: #808000; text-decoration-color: #808000\">Papers</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> | Current <span style=\"color: #808000; text-decoration-color: #808000\">Evidence</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> | Current <span style=\"color: #808000; text-decoration-color: #808000\">Cost</span>=$<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0038</span>                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:55]\u001b[0m\u001b[2;36m \u001b[0mStatus: Paper \u001b[33mCount\u001b[0m=\u001b[1;36m1\u001b[0m | Relevant \u001b[33mPapers\u001b[0m=\u001b[1;36m1\u001b[0m | Current \u001b[33mEvidence\u001b[0m=\u001b[1;36m10\u001b[0m | Current \u001b[33mCost\u001b[0m=$\u001b[1;36m0.0038\u001b[0m                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:56] </span>Completing <span style=\"color: #008000; text-decoration-color: #008000\">'What are the most relevant language models used for chemistry?'</span> as <span style=\"color: #008000; text-decoration-color: #008000\">'certain'</span>.               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:56]\u001b[0m\u001b[2;36m \u001b[0mCompleting \u001b[32m'What are the most relevant language models used for chemistry?'\u001b[0m as \u001b[32m'certain'\u001b[0m.               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Finished agent <span style=\"color: #008000; text-decoration-color: #008000\">'ToolSelector'</span> run with question <span style=\"color: #008000; text-decoration-color: #008000\">'What are the most relevant language models used for </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">chemistry?'</span> and status success.                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mFinished agent \u001b[32m'ToolSelector'\u001b[0m run with question \u001b[32m'What are the most relevant language models used for \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mchemistry?'\u001b[0m and status success.                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Answer: Several language models have emerged as significant tools in the field of chemistry, </span>           \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">particularly for molecular property prediction and design. Notable models include Text2Mol, which </span>      \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">connects natural language descriptions with molecular representations, and MolT5, which generates </span>      \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">molecular captions from Simplified Molecular Input Line Entry System (SMILES) and predicts molecular </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">structures from textual descriptions (Caldas2024 pages </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">). </span>                                         \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                                        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Other important models are CLAMP, which predicts biochemical activity, and BioTranslator, which </span>        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">translates text into biological data (Caldas2024 pages </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">). Additionally, Cappy enhances large </span>      \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">multi-task language models, while iPaucGPT is specifically designed for molecular property prediction </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">and generation (Caldas2024 pages </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">). Tag-LLM repurposes general-purpose models for specialized </span>     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">domains, and NExT-GPT is noted for its multimodal capabilities (Caldas2024 pages </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">).</span>                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                                        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">In the realm of materials science, models like MaterialBERT and SolvBERT focus on natural language </span>     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">processing and predicting solvation free energy, respectively (Caldas2024 pages </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">55</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">). Furthermore, </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">attention-based neural networks and SMILES-BERT are utilized for mapping chemical reactions and </span>        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">predicting molecular properties (Caldas2024 pages </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">). These models collectively enhance the </span>        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">understanding and prediction of chemical behaviors and properties in various applications.</span>              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mAnswer: Several language models have emerged as significant tools in the field of chemistry, \u001b[0m           \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mparticularly for molecular property prediction and design. Notable models include Text2Mol, which \u001b[0m      \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mconnects natural language descriptions with molecular representations, and MolT5, which generates \u001b[0m      \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mmolecular captions from Simplified Molecular Input Line Entry System \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mSMILES\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m and predicts molecular \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mstructures from textual descriptions \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mCaldas2024 pages \u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;34m-\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m. \u001b[0m                                         \n",
       "\u001b[2;36m           \u001b[0m                                                                                                        \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mOther important models are CLAMP, which predicts biochemical activity, and BioTranslator, which \u001b[0m        \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mtranslates text into biological data \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mCaldas2024 pages \u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;34m-\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m. Additionally, Cappy enhances large \u001b[0m      \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mmulti-task language models, while iPaucGPT is specifically designed for molecular property prediction \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mand generation \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mCaldas2024 pages \u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;34m-\u001b[0m\u001b[1;36m51\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m. Tag-LLM repurposes general-purpose models for specialized \u001b[0m     \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mdomains, and NExT-GPT is noted for its multimodal capabilities \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mCaldas2024 pages \u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;34m-\u001b[0m\u001b[1;36m51\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m.\u001b[0m                \n",
       "\u001b[2;36m           \u001b[0m                                                                                                        \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mIn the realm of materials science, models like MaterialBERT and SolvBERT focus on natural language \u001b[0m     \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mprocessing and predicting solvation free energy, respectively \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mCaldas2024 pages \u001b[0m\u001b[1;36m55\u001b[0m\u001b[1;34m-\u001b[0m\u001b[1;36m56\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m. Furthermore, \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mattention-based neural networks and SMILES-BERT are utilized for mapping chemical reactions and \u001b[0m        \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mpredicting molecular properties \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mCaldas2024 pages \u001b[0m\u001b[1;36m58\u001b[0m\u001b[1;34m-\u001b[0m\u001b[1;36m58\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m. These models collectively enhance the \u001b[0m        \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34munderstanding and prediction of chemical behaviors and properties in various applications.\u001b[0m              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from paperqa import ask\n",
    "\n",
    "response = ask(\n",
    "    \"What are the most relevant language models used for chemistry?\", settings=settings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95de705b-8442-470c-a416-8cc28303e63c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "venv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
